library(tidyverse)
library(here)
data_loc <- here("data","output","model_estimation","bayesian_learner")
sub_data <- read.csv(here("data","input","behavioral_data","all_data.csv"))
sub_num_list <- sort(unique(sub_data$sub_num))
## AB
data_loc_ab <- paste0(data_loc, "/single_sub/ab/extracted_data/")
all_ab_data_list <- list()
count_num <- 1
for (i in sub_num_list) {
data_file <- read.csv(paste0(data_loc_ab, "sub_", i, "_ab_learner.csv"))
all_ab_data_list[[count_num]] <- cbind(sub_num = i, data_file)
count_num <- count_num + 1
}
library(tidyverse)
library(here)
data_loc <- here("data","output","model_estimation","bayesian_learner")
sub_data <- read.csv(here("data","input","behavioral_data","all_data.csv"))
sub_num_list <- sort(unique(sub_data$sub_num))
## AB
data_loc_ab <- paste0(data_loc, "/single_sub/ab/extracted_data/")
all_ab_data_list <- list()
count_num <- 1
for (i in sub_num_list) {
data_file <- read.csv(paste0(data_loc_ab, "sub_", i, "_ab_learner.csv"))
all_ab_data_list[[count_num]] <- cbind(sub_num = i, data_file)
count_num <- count_num + 1
}
all_ab_data_result <- bind_rows(all_ab_data_list, .id = "column_label")
all_ab_data_result <- mutate(all_ab_data_result, PE = 1 - r_selected)
colnames(all_ab_data_result) <- paste("ab", colnames(all_ab_data_result), sep = "_")
## SR
data_loc_sr <- paste0(data_loc, "/single_sub/sr/extracted_data/")
all_sr_data_list <- list()
count_num <- 1
for (i in sub_num_list) {
data_file <- read.csv(paste0(data_loc_sr, "sub_", i, "_sr_learner.csv"))
all_sr_data_list[[count_num]] <- cbind(sub_num = i, data_file)
count_num <- count_num + 1
}
all_sr_data_result <- bind_rows(all_sr_data_list, .id = "column_label")
all_sr_data_result <- mutate(all_sr_data_result, PE = 1 - r_selected)
colnames(all_sr_data_result) <- paste("sr", colnames(all_sr_data_result), sep = "_")
## combine two data sets
all_bl_data <- cbind(all_ab_data_result, all_sr_data_result)
write.csv(all_bl_data, here("data","output","model_estimation","bayesian_learner","all_bl_data.csv")
)
library(tidyverse)
library(here)
data_loc <- here("data","output","model_estimation","bayesian_learner")
sub_data <- read.csv(here("data","input","behavioral_data","all_data.csv"))
sub_num_list <- sort(unique(sub_data$sub_num))
## AB
data_loc_ab <- paste0(data_loc, "/single_sub/ab/extracted_data/")
all_ab_data_list <- list()
count_num <- 1
for (i in sub_num_list) {
data_file <- read.csv(paste0(data_loc_ab, "sub_", i, "_ab_learner.csv"))
all_ab_data_list[[count_num]] <- cbind(sub_num = i, data_file)
count_num <- count_num + 1
}
all_ab_data_result <- bind_rows(all_ab_data_list, .id = "column_label")
all_ab_data_result <- mutate(all_ab_data_result, PE = 1 - r_selected)
colnames(all_ab_data_result) <- paste("ab", colnames(all_ab_data_result), sep = "_")
## SR
data_loc_sr <- paste0(data_loc, "/single_sub/sr/extracted_data/")
all_sr_data_list <- list()
count_num <- 1
for (i in sub_num_list) {
data_file <- read.csv(paste0(data_loc_sr, "sub_", i, "_sr_learner.csv"))
all_sr_data_list[[count_num]] <- cbind(sub_num = i, data_file)
count_num <- count_num + 1
}
all_sr_data_result <- bind_rows(all_sr_data_list, .id = "column_label")
all_sr_data_result <- mutate(all_sr_data_result, PE = 1 - r_selected)
colnames(all_sr_data_result) <- paste("sr", colnames(all_sr_data_result), sep = "_")
## combine two data sets
all_bl_data <- cbind(all_ab_data_result, all_sr_data_result)
write.csv(all_bl_data, here("data","output","model_estimation","bayesian_learner","all_bl_data.csv"))
install.packages(c("data.table", "gdtools", "officer"))
library(tidyverse)
library(here)
library(pivottabler)
all_data <- read_csv(here("data", "input", "behavioral_data", "all_data.csv"))
library(mice)
md.pattern(all_data)
all_data_fixed <- mice(all_data, m=5, maxit = 50)
# 反应时
all_data_without_outlier <- all_data %>%
filter(corr_resp == 1) %>%
group_by(sub_num, congruency, prop, volatile) %>%
filter(between(stim_resp.rt, mean(stim_resp.rt, na.rm = TRUE) - (3 * sd(stim_resp.rt, na.rm = TRUE)),
mean(stim_resp.rt, na.rm = TRUE) + (3 * sd(stim_resp.rt, na.rm = TRUE)))) %>%
ungroup()
rt_result_a <- qpvt(all_data_without_outlier, "congruency", "prop", "mean(stim_resp.rt, na.rm = T)")
rt_result_b <- qpvt(all_data_without_outlier, c("rule", "congruency"), "prop", "mean(stim_resp.rt, na.rm = T)")
head(all_data)
glimpse(all_data)
#--- Build a basic function to extract each file
extract_data <- function(file){
raw_data <- read.csv(file)
foo <- raw_data %>%
dplyr::filter(is.na(practice_trials.thisN)) %>%
dplyr::select(sub_num, run, volatile, prop, congruency, stim_image_loc, corr_resp, stim_resp.rt, stim_resp.corr, one_key_resp.started, one_key_resp.rt, stim_image.started, group) %>%
dplyr::filter(!is.na(corr_resp)) %>%
dplyr::mutate(run_begin_time = one_key_resp.started + one_key_resp.rt)
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "prop"])) {
replace_list <- c(replace_list, i)
}else {
foo[replace_list, "prop"] <- foo$prop[i]
replace_list <- c()
}
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "volatile"])) {
replace_list <- c(replace_list, i)
} else {
foo[replace_list, "volatile"] <- foo$volatile[i]
replace_list <- c()
}
add_onset_list <- list()
for (run_num in 1:6) {
tmp_table <- filter(foo, run == run_num)
tmp_table$run_begin_time[2:nrow(tmp_table)] <- tmp_table$run_begin_time[1]
add_onset_list[[run_num]] <- mutate(tmp_table, onset = ((stim_image.started - run_begin_time) / 1.5))
}
foo <- bind_rows(add_onset_list, .id = "run_num")
filterd_data <- foo %>%
dplyr::filter(!is.na(congruency), !is.na(corr_resp))
filterd_data$stim <- str_extract(filterd_data$stim_image_loc, "[bt]o.*") %>% str_remove(".png")
return(cbind(filterd_data,
trial = seq_len(nrow(filterd_data))))
}
#--- Import packages and file list
library(tidyverse)
library(here)
library(writexl)
file_list <- list.files(here("data", "input", "behavioral_data", "single_sub_data"), pattern = ".*.csv", full.names = TRUE)
#--- Extract each csv file
all_data_list <- list()
count_num <- 1
for (i in file_list) {
print(i)
tmp_table <- extract_data(i)
if (tmp_table$sub_num <= 17){
tmp_table$rule = "BR-RL"
} else {
tmp_table$rule = "BL-RR"
}
all_data_list[[count_num]] <- tmp_table
count_num <- count_num + 1
}
#--- Build a basic function to extract each file
extract_data <- function(file){
raw_data <- read.csv(file)
foo <- raw_data %>%
dplyr::filter(is.na(practice_trials.thisN)) %>%
dplyr::select(sub_num, run, volatile, prop, congruency, stim_image_loc, corr_resp, stim_resp.rt, stim_resp.corr, one_key_resp.started, one_key_resp.rt, stim_image.started, group) %>%
dplyr::filter(!is.na(corr_resp)) %>%
dplyr::mutate(run_begin_time = one_key_resp.started + one_key_resp.rt)
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "prop"])) {
replace_list <- c(replace_list, i)
}else {
foo[replace_list, "prop"] <- foo$prop[i]
replace_list <- c()
}
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "volatile"])) {
replace_list <- c(replace_list, i)
} else {
foo[replace_list, "volatile"] <- foo$volatile[i]
replace_list <- c()
}
add_onset_list <- list()
for (run_num in 1:6) {
tmp_table <- filter(foo, run == run_num)
tmp_table$run_begin_time[2:nrow(tmp_table)] <- tmp_table$run_begin_time[1]
add_onset_list[[run_num]] <- mutate(tmp_table, onset = ((stim_image.started - run_begin_time) / 1.5))
}
foo <- bind_rows(add_onset_list, .id = "run_num")
filterd_data <- foo %>%
dplyr::filter(!is.na(congruency), !is.na(corr_resp))
filterd_data$stim <- str_extract(filterd_data$stim_image_loc, "[bt]o.*") %>% str_remove(".png")
return(cbind(filterd_data,
trial = seq_len(nrow(filterd_data))))
}
#--- Import packages and file list
library(tidyverse)
library(here)
library(writexl)
file_list <- list.files(here("data", "input", "behavioral_data", "single_sub_data"), pattern = ".*.csv", full.names = TRUE)
#--- Extract each csv file
all_data_list <- list()
count_num <- 1
for (i in file_list) {
print(i)
tmp_table <- extract_data(i)
if (tmp_table$sub_num[1] <= 17){
tmp_table$rule = "BR-RL"
} else {
tmp_table$rule = "BL-RR"
}
all_data_list[[count_num]] <- tmp_table
count_num <- count_num + 1
}
all_data <- bind_rows(all_data_list, .id = "sub_num") %>%
select(!stim_image_loc) %>%
tidyr::separate(stim, c("stim_loc", "stim_text"), "-")
write_xlsx(all_data, here("data", "output", "behavior", "all_data.xlsx"))
write_csv(all_data, here("data", "output", "behavior", "all_data.csv"))
library(tidyverse)
library(here)
library(pivottabler)
all_data <- read_csv(here("data", "input", "behavioral_data", "all_data.csv"))
# 反应时
all_data_without_outlier <- all_data %>%
filter(corr_resp == 1) %>%
group_by(sub_num, congruency, prop, volatile) %>%
filter(between(stim_resp.rt, mean(stim_resp.rt, na.rm = TRUE) - (3 * sd(stim_resp.rt, na.rm = TRUE)),
mean(stim_resp.rt, na.rm = TRUE) + (3 * sd(stim_resp.rt, na.rm = TRUE)))) %>%
ungroup()
rt_result_a <- qpvt(all_data_without_outlier, "congruency", "prop", "mean(stim_resp.rt, na.rm = T)")
rt_result_b <- qpvt(all_data_without_outlier, c("rule", "congruency"), "prop", "mean(stim_resp.rt, na.rm = T)")
# 反应时
all_data_without_outlier <- all_data %>%
filter(corr_resp == 1) %>%
group_by(sub_num, congruency, prop, volatile, rule) %>%
filter(between(stim_resp.rt, mean(stim_resp.rt, na.rm = TRUE) - (3 * sd(stim_resp.rt, na.rm = TRUE)),
mean(stim_resp.rt, na.rm = TRUE) + (3 * sd(stim_resp.rt, na.rm = TRUE)))) %>%
ungroup()
# 反应时
all_data_without_outlier <- all_data %>%
filter(corr_resp == 1) %>%
group_by(sub_num, congruency, prop, volatile, rule) %>%
filter(between(stim_resp.rt, mean(stim_resp.rt, na.rm = TRUE) -
(3 * sd(stim_resp.rt, na.rm = TRUE)),
mean(stim_resp.rt, na.rm = TRUE) +
(3 * sd(stim_resp.rt, na.rm = TRUE)))) %>%
ungroup()
glimpse(all_data)
library(tidyverse)
library(here)
library(pivottabler)
all_data <- read_csv(here("data", "input", "behavioral_data", "all_data.csv"))
write_csv(all_data, here("data", "input", "behavior", "all_data.csv"))
all_data <- bind_rows(all_data_list, .id = "sub_num") %>%
select(!stim_image_loc) %>%
tidyr::separate(stim, c("stim_loc", "stim_text"), "-")
#--- Build a basic function to extract each file
extract_data <- function(file){
raw_data <- read.csv(file)
foo <- raw_data %>%
dplyr::filter(is.na(practice_trials.thisN)) %>%
dplyr::select(sub_num, run, volatile, prop, congruency, stim_image_loc, corr_resp, stim_resp.rt, stim_resp.corr, one_key_resp.started, one_key_resp.rt, stim_image.started, group) %>%
dplyr::filter(!is.na(corr_resp)) %>%
dplyr::mutate(run_begin_time = one_key_resp.started + one_key_resp.rt)
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "prop"])) {
replace_list <- c(replace_list, i)
}else {
foo[replace_list, "prop"] <- foo$prop[i]
replace_list <- c()
}
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "volatile"])) {
replace_list <- c(replace_list, i)
} else {
foo[replace_list, "volatile"] <- foo$volatile[i]
replace_list <- c()
}
add_onset_list <- list()
for (run_num in 1:6) {
tmp_table <- filter(foo, run == run_num)
tmp_table$run_begin_time[2:nrow(tmp_table)] <- tmp_table$run_begin_time[1]
add_onset_list[[run_num]] <- mutate(tmp_table, onset = ((stim_image.started - run_begin_time) / 1.5))
}
foo <- bind_rows(add_onset_list, .id = "run_num")
filterd_data <- foo %>%
dplyr::filter(!is.na(congruency), !is.na(corr_resp))
filterd_data$stim <- str_extract(filterd_data$stim_image_loc, "[bt]o.*") %>% str_remove(".png")
return(cbind(filterd_data,
trial = seq_len(nrow(filterd_data))))
}
#--- Import packages and file list
library(tidyverse)
library(here)
library(writexl)
file_list <- list.files(here("data", "input", "behavioral_data", "single_sub_data"), pattern = ".*.csv", full.names = TRUE)
#--- Extract each csv file
all_data_list <- list()
count_num <- 1
for (i in file_list) {
print(i)
tmp_table <- extract_data(i)
if (tmp_table$sub_num[1] <= 17){
tmp_table$rule = "BR-RL"
} else {
tmp_table$rule = "BL-RR"
}
all_data_list[[count_num]] <- tmp_table
count_num <- count_num + 1
}
all_data <- bind_rows(all_data_list, .id = "sub_num") %>%
select(!stim_image_loc) %>%
tidyr::separate(stim, c("stim_loc", "stim_text"), "-")
write_xlsx(all_data, here("data", "input", "behavior", "all_data.xlsx"))
rm(list = ls())
#--- Build a basic function to extract each file
extract_data <- function(file){
raw_data <- read.csv(file)
foo <- raw_data %>%
dplyr::filter(is.na(practice_trials.thisN)) %>%
dplyr::select(sub_num, run, volatile, prop, congruency, stim_image_loc, corr_resp, stim_resp.rt, stim_resp.corr, one_key_resp.started, one_key_resp.rt, stim_image.started, group) %>%
dplyr::filter(!is.na(corr_resp)) %>%
dplyr::mutate(run_begin_time = one_key_resp.started + one_key_resp.rt)
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "prop"])) {
replace_list <- c(replace_list, i)
}else {
foo[replace_list, "prop"] <- foo$prop[i]
replace_list <- c()
}
replace_list <- c()
for (i in seq_len(nrow(foo))) {
if (is.na(foo[i, "volatile"])) {
replace_list <- c(replace_list, i)
} else {
foo[replace_list, "volatile"] <- foo$volatile[i]
replace_list <- c()
}
add_onset_list <- list()
for (run_num in 1:6) {
tmp_table <- filter(foo, run == run_num)
tmp_table$run_begin_time[2:nrow(tmp_table)] <- tmp_table$run_begin_time[1]
add_onset_list[[run_num]] <- mutate(tmp_table, onset = ((stim_image.started - run_begin_time) / 1.5))
}
foo <- bind_rows(add_onset_list, .id = "run_num")
filterd_data <- foo %>%
dplyr::filter(!is.na(congruency), !is.na(corr_resp))
filterd_data$stim <- str_extract(filterd_data$stim_image_loc, "[bt]o.*") %>% str_remove(".png")
return(cbind(filterd_data,
trial = seq_len(nrow(filterd_data))))
}
#--- Import packages and file list
library(tidyverse)
library(here)
library(writexl)
file_list <- list.files(here("data", "input", "behavioral_data", "single_sub_data"), pattern = ".*.csv", full.names = TRUE)
#--- Extract each csv file
all_data_list <- list()
count_num <- 1
for (i in file_list) {
print(i)
tmp_table <- extract_data(i)
if (tmp_table$sub_num[1] <= 17){
tmp_table$rule = "BR-RL"
} else {
tmp_table$rule = "BL-RR"
}
all_data_list[[count_num]] <- tmp_table
count_num <- count_num + 1
}
all_data <- bind_rows(all_data_list, .id = "sub_num") %>%
select(!stim_image_loc) %>%
tidyr::separate(stim, c("stim_loc", "stim_text"), "-")
write_xlsx(all_data, here("data", "input", "behavioral_data", "all_data.xlsx"))
write_csv(all_data, here("data", "input", "behavioral_data", "all_data.csv"))
rm(list = ls())
library(tidyverse)
library(here)
library(pivottabler)
all_data <- read_csv(here("data", "input", "behavioral_data", "all_data.csv"))
# library(mice)
# md.pattern(all_data)
# all_data_fixed <- mice(all_data, m=5, maxit = 50)
# summary(all_data_fixed)
# all_data_for_beh <- complete(all_data_fixed)
# 反应时
all_data_without_outlier <- all_data %>%
filter(corr_resp == 1) %>%
group_by(sub_num, congruency, prop, volatile, rule) %>%
filter(between(stim_resp.rt, mean(stim_resp.rt, na.rm = TRUE) -
(3 * sd(stim_resp.rt, na.rm = TRUE)),
mean(stim_resp.rt, na.rm = TRUE) +
(3 * sd(stim_resp.rt, na.rm = TRUE)))) %>%
ungroup()
rt_result_a <- qpvt(all_data_without_outlier,
"congruency", "prop",
"mean(stim_resp.rt, na.rm = T)")
rt_result_b <- qpvt(all_data_without_outlier,
c("rule", "congruency"), "prop",
"mean(stim_resp.rt, na.rm = T)")
rt_result_c <- qpvt(all_data_without_outlier,
c("volatile", "congruency"), "prop",
"mean(stim_resp.rt, na.rm = T)")
rt_result_a
rt_result_b
rt_result_c
# 正确率
foo <- filter(all_data_for_beh, sub_num > 8)
# 正确率
foo <- filter(all_data_without_outlier, sub_num > 8)
corr_result_a <- qpvt(foo, "congruency", "prop",
"mean(stim_resp.corr, na.rm = T)")
corr_result_b <- qpvt(foo, c("rule", "congruency"), "prop",
"mean(stim_resp.corr, na.rm = T)")
corr_result_b <- qpvt(foo, c("rule", "congruency"), "prop",
"mean(stim_resp.corr, na.rm = T)")
corr_result_c <- qpvt(foo, c("volatile", "congruency"), "prop",
"mean(stim_resp.corr, na.rm = T)")
corr_result_a
corr_result_b
corr_result_c
total_result_list <- list(rt_result_a$asDataFrame(),
rt_result_b$asDataFrame(),
rt_result_c$asDataFrame(),
corr_result_a$asDataFrame(),
corr_result_b$asDataFrame(),
corr_result_c$asDataFrame())
rt_result_b <- qpvt(all_data_without_outlier,
c("rule", "congruency"), "prop",
"mean(stim_resp.rt, na.rm = T)")
rt_result_b
# Delta plot
source(here("script", "beh", "delta_plot.R"))
single_sub_stroop_list <- list()
for (i in unique(all_data$sub_num)) {
tmp_data <- filter(all_data_without_outlier, sub_num == i)
print(paste("The subject is", i))
single_stroop_result <- qpvt(tmp_data, c("volatile", "congruency"), "prop", "mean(rt)")
print(single_stroop_result)
foo <- single_stroop_result$asDataFrame()
foo <- cbind(foo[c(1,2,4,5),1:2],
volatile = c("s", "s", "v", "v"),
congruency = c("con", "inc", "con", "inc"))
foo %>% tidyr::pivot_longer(cols = c("MC", "MI"), names_to = "prop", values_to = "mean_rt") %>%
pivot_wider(names_from = congruency, values_from = mean_rt) %>%
group_by(prop, volatile) %>%
summarise(stroop_effect = inc - con) %>%
tidyr::pivot_wider(names_from = prop, values_from = stroop_effect) -> bar
foo$idx <- c(1,2,4,5)
bar <- cbind(bar, congruency = rep("stroop_effect",2), idx = c(3,6))
result <- cbind(rbind(foo, bar), sub_num = i) %>% arrange(idx)
single_sub_stroop_list[[i]] <- result
}
single_sub_stroop_table <- bind_rows(single_sub_stroop_list, .id = "column_label")
write_xlsx(single_sub_stroop_table, here("output", "single_sub_stroop.xlsx"))
single_sub_stroop_list <- list()
i= 1
# for (i in unique(all_data$sub_num)) {
tmp_data <- filter(all_data_without_outlier, sub_num == i)
tmp_data
glimpse(single_stroop_result)
glimpse(tmp_data)
single_stroop_result <- qpvt(tmp_data, c("volatile", "congruency"), "prop", "mean(rt)")
single_stroop_result <- qpvt(tmp_data, c("volatile", "congruency"), "prop",
"mean(stim_resp.rt, na.rm = T)")
print(single_stroop_result)
foo <- single_stroop_result$asDataFrame()
foo <- cbind(foo[c(1,2,4,5),1:2],
volatile = c("s", "s", "v", "v"),
congruency = c("con", "inc", "con", "inc"))
foo %>% tidyr::pivot_longer(cols = c("MC", "MI"),
names_to = "prop",
values_to = "mean_rt") %>%
pivot_wider(names_from = congruency,
values_from = mean_rt) %>%
group_by(prop, volatile) %>%
summarise(stroop_effect = inc - con) %>%
tidyr::pivot_wider(names_from = prop,
values_from = stroop_effect) -> bar
foo$idx <- c(1,2,4,5)
bar <- cbind(bar, congruency = rep("stroop_effect",2), idx = c(3,6))
result <- cbind(rbind(foo, bar), sub_num = i) %>% arrange(idx)
single_sub_stroop_list[[i]] <- result
single_sub_stroop_list <- list()
for (i in unique(all_data$sub_num)) {
tmp_data <- filter(all_data_without_outlier, sub_num == i)
print(paste("The subject is", i))
single_stroop_result <- qpvt(tmp_data, c("volatile", "congruency"), "prop",
"mean(stim_resp.rt, na.rm = T)")
print(single_stroop_result)
foo <- single_stroop_result$asDataFrame()
foo <- cbind(foo[c(1,2,4,5),1:2],
volatile = c("s", "s", "v", "v"),
congruency = c("con", "inc", "con", "inc"))
foo %>% tidyr::pivot_longer(cols = c("MC", "MI"),
names_to = "prop",
values_to = "mean_rt") %>%
pivot_wider(names_from = congruency,
values_from = mean_rt) %>%
group_by(prop, volatile) %>%
summarise(stroop_effect = inc - con) %>%
tidyr::pivot_wider(names_from = prop,
values_from = stroop_effect) -> bar
foo$idx <- c(1,2,4,5)
bar <- cbind(bar, congruency = rep("stroop_effect",2), idx = c(3,6))
result <- cbind(rbind(foo, bar), sub_num = i) %>% arrange(idx)
single_sub_stroop_list[[i]] <- result
}
single_sub_stroop_table <- bind_rows(single_sub_stroop_list, .id = "column_label")
write_xlsx(single_sub_stroop_table, here("output", "single_sub_stroop.xlsx"))
write_xlsx(single_sub_stroop_table, here("data", "output",
"behavior", "single_sub_stroop.xlsx"))
